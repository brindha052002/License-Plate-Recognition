{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e74b19-8a4f-478a-89f8-1931a7fc3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow==2.7.0  # Ensure to use compatible version\n",
    "!pip install tf_slim\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759409a8-dde0-4b15-bd29-ca538822a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the TensorFlow Models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8c28e-d0d4-4309-a3e5-3da477991650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Object Detection API\n",
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=\n",
    "cp object_detection/packages/tf2/setup.py\n",
    "python -m pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264d22f-8d86-4a48-9839-434cf5b6720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import colab_utils\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164786c-5cca-486a-acfc-bd88b5410137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your pipeline config file\n",
    "pipeline_config_path = 'path' # adding file path\n",
    "\n",
    "# Path to your checkpoint directory\n",
    "model_dir = 'path' # adding file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27436ea1-e963-432f-a506-55fc4ffcfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef17a75-80e1-40a2-b2d0-918e6177055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584919d-891a-4d03-87ad-5ed92c79582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a6210-f806-49fd-8bb6-6904c333a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (640, 640))  # Resize to match model's expected sizing\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb7c8c-31d4-4b78-8d80-0fddef6c8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect license plates in an image\n",
    "def detect_license_plate(image_path):\n",
    "    image_np = preprocess_image(image_path)\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    detections = detection_model(input_tensor)\n",
    "    detection_boxes = detections['detection_boxes'][0].numpy()\n",
    "    detection_scores = detections['detection_scores'][0].numpy()\n",
    "    detection_classes = detections['detection_classes'][0].numpy().astype(int)\n",
    "\n",
    "    # Filter detections to only include license plates\n",
    "    license_plate_boxes = detection_boxes[detection_classes == 1]  # Assuming class 1 is license plate\n",
    "\n",
    "    return license_plate_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9794256-9b37-43a4-9e2c-178fb16758ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_path = 'path' # adding file path\n",
    "license_plate_boxes = detect_license_plate(image_path)\n",
    "print(\"Detected license plate bounding boxes:\", license_plate_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f666809-46c5-4852-a91a-c1e59ab111f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install torch torchvision matplotlib opencv-python\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "\n",
    "# Define a simple CNN model for character recognition\n",
    "class CharacterRecognizerCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharacterRecognizerCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 36)  # Assuming 36 classes for alphanumeric characters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.conv1(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        x = torch.nn.functional.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load pretrained model weights\n",
    "model = CharacterRecognizerCNN()\n",
    "model.load_state_dict(torch.load('path/to/your/model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess license plate image\n",
    "def preprocess_license_plate(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (64, 64))  # Resize to match model's expected input size\n",
    "    image = transforms.functional.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to recognize characters on a license plate\n",
    "def recognize_characters(image_path):\n",
    "    image = preprocess_license_plate(image_path)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_char = chr(predicted.item() + 65)  # Convert numeric class to character (assuming class 0-25 are A-Z)\n",
    "    return predicted_char\n",
    "\n",
    "# Example usage:\n",
    "license_plate_image_path = 'path/to/your/license_plate_image.jpg'\n",
    "predicted_character = recognize_characters(license_plate_image_path)\n",
    "print(\"Predicted character on license plate:\", predicted_character)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
